{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas(desc='apply')\n",
    "\n",
    "from random import sample\n",
    "import dill\n",
    "import re\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse and cache .zip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _no_location(df):\n",
    "    truth = np.array(df['region'].isna().tolist() and df['locality'].isna().tolist())\n",
    "    idx = df[truth].index\n",
    "    df.drop(idx, inplace=True)\n",
    "    return None\n",
    "\n",
    "def _abrv_states(df):\n",
    "    df['region'] = df['region'].str.upper().replace(states_dict)\n",
    "    return None\n",
    "\n",
    "def _in_usa(df):\n",
    "    truth = df[['region']].isin(states_dict.values())['region']\n",
    "    idx = df[~truth].index\n",
    "    df.drop(idx, inplace=True)\n",
    "    return None\n",
    "\n",
    "def _has_title(df):\n",
    "    df.dropna(subset=['title'], inplace=True)\n",
    "    return None\n",
    "\n",
    "def _combine_dates(df):\n",
    "    df['posted_date'].fillna(df['date_added'], inplace=True)\n",
    "    df.drop('date_added', axis=1, inplace=True)\n",
    "    df.rename(columns={'posted_date': 'date'}, inplace=True)\n",
    "    return None\n",
    "\n",
    "def _has_dates(df, columns):\n",
    "    df.dropna(subset=columns, how='all', inplace=True)\n",
    "    return None\n",
    "\n",
    "def _date_parser(s):\n",
    "    output = pd.to_datetime(s, format='%Y-%m-%d', errors='coerce')\n",
    "    return output\n",
    "\n",
    "def _clean_and_save_chunk(file, num=0, **kwargs):\n",
    "    for chunk in pd.read_csv(file, **kwargs):\n",
    "        _has_title(chunk)\n",
    "        _has_dates(chunk, columns=date_cols)\n",
    "        _abrv_states(chunk)\n",
    "        _in_usa(chunk)\n",
    "        chunk.reset_index(drop=True).to_feather('raw_cache/data_{}.feather'.format(num))\n",
    "        num += 1\n",
    "    return num\n",
    "\n",
    "def cache_files(files, num=0, **kwargs):\n",
    "    for file in tqdm(files, desc='zip files'):\n",
    "        num = _clean_and_save_chunk(file, num=num, **kwargs)\n",
    "    return None\n",
    "\n",
    "def _get_df(file, **kwargs):\n",
    "    df = pd.read_feather(file, **kwargs)\n",
    "    _within_range(df)\n",
    "    df.dropna(subset=['posted_date'], inplace=True)\n",
    "    return df\n",
    "\n",
    "def _within_range(df):\n",
    "    start = pd.datetime(2017, 1, 1)\n",
    "    end = pd.datetime(2018, 7, 1)\n",
    "    truth = ~df['posted_date'].isin(pd.date_range(start, end))\n",
    "    df.drop(df[truth].index, inplace=True)\n",
    "\n",
    "def _add_day_of_week(df):\n",
    "    days = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday']\n",
    "    df['day_of_week'] = pd.Categorical(df['posted_date'].dt.day_name(), categories=days, ordered=True)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/garychen/anaconda3/envs/TDI/lib/python3.7/site-packages/pyarrow/pandas_compat.py:752: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels, = index.labels\n"
     ]
    }
   ],
   "source": [
    "pop = pd.read_feather('other_data/census.feather')\n",
    "states = pd.read_feather('other_data/us_states.feather')\n",
    "states_dict = states.set_index('STATE').to_dict()['Abrv']\n",
    "\n",
    "zip_columns = ['title', 'brand', 'category', 'locality', 'region', 'date_added', 'posted_date']\n",
    "date_cols = ['date_added', 'posted_date']\n",
    "\n",
    "start = pd.datetime(2017, 12, 1)\n",
    "end = pd.datetime(2018, 7, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac11149672e420aac28d52555acb444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='zip files', max=7, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "folder = 'raw_zips'\n",
    "files = [os.path.join(folder, file) for file in os.listdir(folder)]\n",
    "cache_files(files, usecols=zip_columns, chunksize=1e7, compression='infer', dtype=str, parse_dates=date_cols, date_parser=_date_parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group data\n",
    "\n",
    "Group by day, week, state, and city over time and cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed3e7d04408b4adc97fa9c28aa9df806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='feather_files', max=41, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "job_counts = None\n",
    "folder = 'raw_cache'\n",
    "files = [os.path.join(folder, file) for file in os.listdir(folder) if file.endswith('.feather')]\n",
    "\n",
    "for file in tqdm(files, desc='feather_files'):\n",
    "    df = _get_df(file, columns=['locality', 'region', 'posted_date'])\n",
    "    df['posts'] = 1\n",
    "    grouped = df.groupby(['locality', 'region', 'posted_date']).sum()\n",
    "    if job_counts is None:\n",
    "        job_counts = pd.Series()\n",
    "        job_counts.name = 'posts'\n",
    "        job_counts = job_counts.add(grouped['posts'], level='locality', fill_value=0)\n",
    "    else:\n",
    "        job_counts = job_counts.add(grouped['posts'], fill_value=0)\n",
    "        \n",
    "job_counts = job_counts.reset_index()\n",
    "job_counts['posts'] = job_counts['posts'].astype(int)\n",
    "job_counts.to_feather('grouped/job_counts.feather')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
